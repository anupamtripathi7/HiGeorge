{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e0a1c2",
   "metadata": {},
   "source": [
    "<h1>Part 2: Data Analysis of Rent Price Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b06db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c0f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7171108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/renthub_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4696eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unwanted colomn to save on processing time\n",
    "del df['marketing_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a107ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530038b",
   "metadata": {},
   "source": [
    "## Dealing with duplicate values\n",
    "For duplicate values, we need to delete only the ones that have same posted dates, since a unit can be listed multiple times over years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec7d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(\n",
    "    subset = ['address', 'sqft', 'lat', 'long', 'posted_at'],\n",
    "    keep = 'first').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bfa8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cdb8b8",
   "metadata": {},
   "source": [
    "Our new dataset contains much lesser number of rows. It is around 1/10th of our original data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037e2d5",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "Lets see the stats for the difference between the date posted and the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47127af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posted_at'] = pd.to_datetime(df['posted_at'])\n",
    "df['scraped_at'] = pd.to_datetime(df['scraped_at'])\n",
    "df['posted_difference'] = df['scraped_at'] - df['posted_at']\n",
    "print('99th percentile: ', df['posted_difference'].quantile(0.99))\n",
    "df['posted_difference'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630853c",
   "metadata": {},
   "source": [
    "With a standard deviation of around 15 days, units with posted difference of greater than 90 days can be considered as outliers and be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['posted_difference'].astype('timedelta64[D]') <= 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90576f",
   "metadata": {},
   "source": [
    "<br>Not all zip codes contain the same number of houses, so we need to remove the ones that contain number of houses less than a certain threshold. To get this threshold, we will need to visualize this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07868700",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby(by=\"zip\").id.count()\n",
    "print(len(counts))\n",
    "counts = counts[counts < 10]\n",
    "_ = plt.hist(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e7eb4",
   "metadata": {},
   "source": [
    "Out of around 60,000 zipcodes in our dataset, around 40,000 have 2 or lesser number of entries. We will be considering only the ones that have 3 or more entires since the graphs that we are targeting need to have multiple entries. Also for aggregation metrics, all types of metrics can be dominated by outliers for even 2 entires and so we need at least 3. This may look like dropping a lot of rows, but in reality they make up a really small part of our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ee57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['zip'].isin(counts[counts < 3].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5a32b",
   "metadata": {},
   "source": [
    "This is not enough. We also need to remove the zip codes that have just one distinct month in them, since the intended visualization in that case will be just be a single point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7df294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['posted_month'] = df['posted_at'].dt.date + pd.offsets.MonthEnd(0) - pd.offsets.MonthBegin(1)\n",
    "df_zip_month = df[['id', 'zip', 'posted_month']].drop_duplicates()\n",
    "zip_month_counts = df_zip_month.groupby('zip')['id'].count()\n",
    "zip_month_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_month_counts = zip_month_counts[zip_month_counts >= 2]\n",
    "df = df[~df['zip'].isin(zip_month_counts.index)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e174d0",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Any row will nan in the zip column or posted at column needs to be removed. <br> We have few rows that have non alphanumeric characters in zip code column, so we need to remove those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.zip.notna()]\n",
    "df = df[df.posted_at.notna()]\n",
    "df = df[~df.zip.str.contains(r'[^\\w\\s]', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a166e",
   "metadata": {},
   "source": [
    "## Create featues for appropirate graphs\n",
    "Below given function transforms the data in the best way posible to be visualized in the format provided in the example. It takes the zip code we want to visialize for as an argument. We can make multiple calls in case of multiple zip codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de017f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_on_attribute(df, zip_code, col, agg='mean'):\n",
    "    df = df[df['zip'] == zip_code]\n",
    "    df_1 = df[['id', col, 'posted_at', 'zip']]\n",
    "    df_1['month'] = (df_1['posted_at'] + pd.offsets.MonthBegin(1)).dt.date\n",
    "    df_2 = df[['id', col, 'posted_at', 'zip']]\n",
    "    df_2['month'] = (df_2['posted_at'] + pd.offsets.MonthBegin(2)).dt.date\n",
    "    df_3 = df[['id', col, 'posted_at', 'zip']]\n",
    "    df_3['month'] = (df_3['posted_at'] + pd.offsets.MonthBegin(3)).dt.date\n",
    "    df_features = pd.concat([df_1, df_2, df_3])\n",
    "    if agg == 'mean':\n",
    "        grouped_df = df_features.groupby(by='month')[col].mean()\n",
    "    elif agg == 'max':\n",
    "        grouped_df = df_features.groupby(by='month')[col].max()\n",
    "    elif agg == 'min':\n",
    "        grouped_df = df_features.groupby(by='month')[col].min()\n",
    "    else:\n",
    "        print('agg can be one of mean, min, max')\n",
    "        return\n",
    "    return grouped_df\n",
    "df_features = aggregate_on_attribute(df, 10001, 'price', 'mean')\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa340157",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb90dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple zip codes\n",
    "\n",
    "for zip_code in [85741, 85716, 85718, 85711, 85712]:\n",
    "    plt.plot(aggregate_on_attribute(df, zip_code, 'price', 'mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72150b9",
   "metadata": {},
   "source": [
    "Summary:\n",
    "- The ETL pipeline given above reads data, removes all unwanted rows, features and duplicates, and finally puts in such a format that visualization is easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473f29e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
